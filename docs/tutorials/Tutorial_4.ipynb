{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664bfe29-de10-4c07-b23e-75bdb9a330d3",
   "metadata": {},
   "source": [
    "### Tutorial 4 - How Create an Agnostic Pipeline\n",
    "\n",
    "In this tutorial, we will show you how convert a simple code structure into a advanced and agnostic pipeline based on DAGs.\n",
    "\n",
    "For this, we still can use the **Tutorial 1** with a simple Machine Learning script. There we use `make_blobs` to generate a dataset and them we cluster it using two algorithms: KMeans and SOM.\n",
    "\n",
    "First, let's generate and save our data (you can use DASF or Scikit-learn). The objective here is just to generate some labeled data and use the `DatasetLabeled` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3ae542-b03f-49e0-86fc-1cdbf19b5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dasf.datasets import make_blobs\n",
    "\n",
    "n_samples = 500000\n",
    "n_bins = 3\n",
    "\n",
    "# Generate 3 blobs with 2 classes where the second blob contains\n",
    "# half positive samples and half negative samples. Probability in this\n",
    "# blob is therefore 0.5.\n",
    "centers = [(-6, -6), (0, 0), (9, 1)]\n",
    "X, y = make_blobs(n_samples=n_samples, centers=centers, shuffle=False, random_state=42)\n",
    "\n",
    "np.save(\"X.npy\", X)\n",
    "np.save(\"y.npy\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e6b0b-236d-4cab-951b-e973e780c94f",
   "metadata": {},
   "source": [
    "Now, let's import our `DatasetLabeled` and assign each file to the respective type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5d935f-065e-4bda-af74-38b148924463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dasf.datasets import DatasetArray\n",
    "from dasf.datasets import DatasetLabeled\n",
    "\n",
    "\n",
    "class MyMakeBlobs(DatasetLabeled):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"My Own make_blobs()\", download=False)\n",
    "        \n",
    "        # Let's assign the train and val data.\n",
    "        self._train = DatasetArray(name=\"X\", download=False, root=\"X.npy\")\n",
    "        self._val = DatasetArray(name=\"y\", download=False, root=\"y.npy\")\n",
    "\n",
    "make_blobs = MyMakeBlobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bcedef-d5cb-40ee-a691-dcb2d1636083",
   "metadata": {},
   "source": [
    "To reduce the variability and as an example, we can normalize the data to help the algorithms to fit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db9235f-7580-48dd-a9e9-b946a9570a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dasf.transforms import Normalize\n",
    "\n",
    "normalize = Normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaed4e1-b799-4448-99ac-922094b18988",
   "metadata": {},
   "source": [
    "After, creating our dataset and the normalization transformation, we can start the executor. For this example, we can use Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa39f7b9-ffb1-4c93-9293-ecda4139d8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 01:31:53,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-41q8cz3m', purging\n",
      "2022-10-02 01:31:53,167 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-xokbnpvc', purging\n",
      "2022-10-02 01:31:53,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-mpyzht0m', purging\n",
      "2022-10-02 01:31:53,168 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-c1r1m7sj', purging\n"
     ]
    }
   ],
   "source": [
    "from dasf.pipeline.executors import DaskPipelineExecutor\n",
    "\n",
    "dask = DaskPipelineExecutor(local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd517c3-8de0-46a4-89c4-78314ffe6491",
   "metadata": {},
   "source": [
    "Now, it is time to create our pipeline objects. We can copy and paste the same code used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3fc983-f6c8-4a66-9a22-fc1a6b5ccd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CuPy could not be imported\n",
      "WARNING: CuPy could not be imported\n",
      "WARNING: CuPy could not be imported\n"
     ]
    }
   ],
   "source": [
    "from dasf.ml.cluster import KMeans\n",
    "from dasf.ml.cluster import SOM\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, max_iter=100)\n",
    "som = SOM(x=1, y=3, input_len=2, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b26ce69-d483-4ec3-a570-cfa761299983",
   "metadata": {},
   "source": [
    "Then, we generate the pipeline and connect all the pieces in one single DAG.\n",
    "\n",
    "Pay attention that we are passing the our fresh executor `dask` to the pipeline by specifying the parameter `executor=`.\n",
    "\n",
    "To connect all the objects, we use the function `add()` that returns the pipeline itself. The function inputs can be refered as an argument.\n",
    "\n",
    "At the end, we can visualize the DAG using `visualize()` method. It will plot a image that represents the graph. Let's use one single line to do everything. It should be simple and easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbee98cf-2425-431f-87af-342fcf0c00c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: A KMeans and SOM Pipeline Pages: 1 -->\n",
       "<svg width=\"392pt\" height=\"218pt\"\n",
       " viewBox=\"0.00 0.00 391.63 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\n",
       "<title>A KMeans and SOM Pipeline</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-214 387.63,-214 387.63,4 -4,4\"/>\n",
       "<!-- DatasetArray.load -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>DatasetArray.load</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"198.79\" cy=\"-192\" rx=\"93.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"198.79\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">DatasetArray.load</text>\n",
       "</g>\n",
       "<!-- Normalize.transform -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Normalize.transform</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"198.79\" cy=\"-105\" rx=\"107.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"198.79\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normalize.transform</text>\n",
       "</g>\n",
       "<!-- DatasetArray.load&#45;&gt;Normalize.transform -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>DatasetArray.load&#45;&gt;Normalize.transform</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.79,-173.8C198.79,-162.16 198.79,-146.55 198.79,-133.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.29,-133.18 198.79,-123.18 195.29,-133.18 202.29,-133.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"203.79\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- KMeans.fit_predict -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>KMeans.fit_predict</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"98.79\" cy=\"-18\" rx=\"98.58\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.79\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">KMeans.fit_predict</text>\n",
       "</g>\n",
       "<!-- Normalize.transform&#45;&gt;KMeans.fit_predict -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Normalize.transform&#45;&gt;KMeans.fit_predict</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.03,-87.21C163.97,-74.4 143.03,-56.61 126.33,-42.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.39,-39.57 118.51,-35.76 123.86,-44.9 128.39,-39.57\"/>\n",
       "<text text-anchor=\"middle\" x=\"159.79\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- SOM.fit_predict -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>SOM.fit_predict</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"299.79\" cy=\"-18\" rx=\"83.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"299.79\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">SOM.fit_predict</text>\n",
       "</g>\n",
       "<!-- Normalize.transform&#45;&gt;SOM.fit_predict -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Normalize.transform&#45;&gt;SOM.fit_predict</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M218.75,-87.21C233.96,-74.4 255.11,-56.61 271.98,-42.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.48,-44.88 279.88,-35.76 269.97,-39.52 274.48,-44.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"260.79\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fbf12f99640>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dasf.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\"A KMeans and SOM Pipeline\", executor=dask)\n",
    "\n",
    "pipeline.add(normalize, X=make_blobs._train) \\\n",
    "        .add(kmeans.fit_predict, X=normalize) \\\n",
    "        .add(som.fit_predict, X=normalize) \\\n",
    "        .visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14815700-715b-4e17-92e0-1203b107c7c8",
   "metadata": {},
   "source": [
    "It is time to run our new pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2dd0613-ccbf-4543-bd01-ba3dda54fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-02 01:31:53-0300] INFO - Beginning pipeline run for 'A KMeans and SOM Pipeline'\n",
      "[2022-10-02 01:31:53-0300] INFO - Task 'DatasetArray.load': Starting task run...\n",
      "[2022-10-02 01:31:53-0300] INFO - Task 'DatasetArray.load': Finished task run\n",
      "[2022-10-02 01:31:53-0300] INFO - Task 'Normalize.transform': Starting task run...\n",
      "[2022-10-02 01:31:53-0300] INFO - Task 'Normalize.transform': Finished task run\n",
      "[2022-10-02 01:31:53-0300] INFO - Task 'KMeans.fit_predict': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/dask/base.py:1365: UserWarning: Running on a single-machine scheduler when a distributed client is active might lead to unexpected results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-02 01:32:00-0300] INFO - Task 'KMeans.fit_predict': Finished task run\n",
      "[2022-10-02 01:32:00-0300] INFO - Task 'SOM.fit_predict': Starting task run...\n",
      "[2022-10-02 01:32:18-0300] INFO - Task 'SOM.fit_predict': Finished task run\n",
      "[2022-10-02 01:32:18-0300] INFO - Pipeline run successfully\n",
      "CPU times: user 4.46 s, sys: 898 ms, total: 5.36 s\n",
      "Wall time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "%time pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8f9cb-de3e-4e9e-bf9f-3d89f59e99ba",
   "metadata": {},
   "source": [
    "Notice that our pipeline returns two methods instead of one. To capture the result of some node, you can easily pass the same function or object to the pipeline function `get_result_from()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3412afd-4f97-4219-954a-5d95cf92d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_kmeans = pipeline.get_result_from(kmeans.fit_predict).compute()\n",
    "result_som = pipeline.get_result_from(som.fit_predict).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801faa7c-a1c4-48c9-9c6c-de2c480a74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(X, result):\n",
    "    y_unique = np.unique(result)\n",
    "    \n",
    "    colors = cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "    \n",
    "    for this_y, color in zip(y_unique, colors):\n",
    "        this_X = X[result == this_y]\n",
    "        plt.scatter(\n",
    "            this_X[:, 0],\n",
    "            this_X[:, 1],\n",
    "            s=50,\n",
    "            c=color[np.newaxis, :],\n",
    "            alpha=0.5,\n",
    "            edgecolor=\"k\",\n",
    "            label=\"Class %s\" % this_y,\n",
    "        )\n",
    "\n",
    "plot_results(make_blobs._train, result_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe23cb-d5ae-4255-9437-42cddb89d004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
